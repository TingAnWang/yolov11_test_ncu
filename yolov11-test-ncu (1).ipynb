{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9583559,"sourceType":"datasetVersion","datasetId":5843955}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-09T02:20:27.644515Z","iopub.execute_input":"2024-10-09T02:20:27.644825Z","iopub.status.idle":"2024-10-09T02:20:28.781382Z","shell.execute_reply.started":"2024-10-09T02:20:27.644792Z","shell.execute_reply":"2024-10-09T02:20:28.780288Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Due to a lack of gpu, I choose to test yolov11 on kaggle with p100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# install torch to use pytorch\n!pip install torch","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:40:07.434810Z","iopub.execute_input":"2024-10-09T06:40:07.435120Z","iopub.status.idle":"2024-10-09T06:40:20.415106Z","shell.execute_reply.started":"2024-10-09T06:40:07.435086Z","shell.execute_reply":"2024-10-09T06:40:20.413995Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# import opencv\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2024-10-10T09:31:18.801957Z","iopub.execute_input":"2024-10-10T09:31:18.802613Z","iopub.status.idle":"2024-10-10T09:31:18.806763Z","shell.execute_reply.started":"2024-10-10T09:31:18.802565Z","shell.execute_reply":"2024-10-10T09:31:18.805738Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.test.is_gpu_available())\nprint(tf.test.is_built_with_cuda())\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T09:31:20.856704Z","iopub.execute_input":"2024-10-10T09:31:20.857559Z","iopub.status.idle":"2024-10-10T09:31:20.873212Z","shell.execute_reply.started":"2024-10-10T09:31:20.857517Z","shell.execute_reply":"2024-10-10T09:31:20.871776Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"False\nTrue\n","output_type":"stream"}]},{"cell_type":"code","source":"# install ultralytics to use yolov11\n!pip install ultralytics","metadata":{"execution":{"iopub.status.busy":"2024-10-10T09:31:24.320349Z","iopub.execute_input":"2024-10-10T09:31:24.320984Z","iopub.status.idle":"2024-10-10T09:31:36.027681Z","shell.execute_reply.started":"2024-10-10T09:31:24.320943Z","shell.execute_reply":"2024-10-10T09:31:36.026403Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: ultralytics in /opt/conda/lib/python3.10/site-packages (8.3.9)\nRequirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (10.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.14.1)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.4.0)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.19.0)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: ultralytics-thop>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.9)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy\nimport pandas","metadata":{"execution":{"iopub.status.busy":"2024-10-10T09:31:36.030027Z","iopub.execute_input":"2024-10-10T09:31:36.030398Z","iopub.status.idle":"2024-10-10T09:31:36.034753Z","shell.execute_reply.started":"2024-10-10T09:31:36.030360Z","shell.execute_reply":"2024-10-10T09:31:36.033831Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# # testing\n# from ultralytics import YOLO\n\n# # Load a model\n# model = YOLO(\"yolo11n.pt\")\n\n# # Train the model\n# train_results = model.train(\n#     data=\"coco8.yaml\",  # path to dataset YAML\n#     epochs=100,  # number of training epochs\n#     imgsz=640,  # training image size\n#     device=\"cpu\",  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu\n# )\n\n# # Evaluate model performance on the validation set\n# metrics = model.val()\n\n# # # Perform object detection on an image\n# # results = model(\"path/to/image.jpg\")\n# # results[0].show()\n\n# # # Export the model to ONNX format\n# # path = model.export(format=\"onnx\")  # return path to exported model","metadata":{"execution":{"iopub.status.busy":"2024-10-09T03:48:17.135708Z","iopub.execute_input":"2024-10-09T03:48:17.136686Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Ultralytics 8.3.8 ðŸš€ Python-3.10.14 torch-2.4.0 CPU (Intel Xeon 2.00GHz)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=coco8.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \nYOLO11n summary: 319 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n\nTransferred 499/499 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtimmywang0207\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241009_034817-ugi96bfu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/timmywang0207/YOLOv8/runs/ugi96bfu' target=\"_blank\">train3</a></strong> to <a href='https://wandb.ai/timmywang0207/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/timmywang0207/YOLOv8' target=\"_blank\">https://wandb.ai/timmywang0207/YOLOv8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/timmywang0207/YOLOv8/runs/ugi96bfu' target=\"_blank\">https://wandb.ai/timmywang0207/YOLOv8/runs/ugi96bfu</a>"},"metadata":{}},{"name":"stdout","text":"Freezing layer 'model.23.dfl.conv.weight'\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train3/labels.jpg... \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 0 dataloader workers\nLogging results to \u001b[1mruns/detect/train3\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/100         0G      1.365      3.625      1.786         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17       0.56       0.85       0.88      0.636\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/100         0G      1.181      2.736      1.443         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.53s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.86it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.559       0.85      0.892      0.638\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/100         0G      1.073      2.641      1.224         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.45s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.555       0.85      0.854      0.653\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/100         0G      1.254       3.31      1.567         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.47s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.539       0.85      0.856      0.655\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/100         0G      1.214      3.001      1.485         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.43s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.535       0.85      0.878      0.641\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/100         0G       0.99      2.694      1.333         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.49s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.548       0.85      0.878      0.641\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/100         0G     0.8189      2.642      1.309         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.822       0.65      0.858       0.63\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/100         0G      1.354      2.951      1.587         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.52s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.86it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.553      0.866       0.86      0.629\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      9/100         0G      1.018      2.218      1.433         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.49s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.551      0.867      0.872      0.631\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     10/100         0G     0.9819      2.952      1.376         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.91it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.589      0.867      0.887      0.631\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     11/100         0G       1.21       2.58      1.499         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.59s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.584      0.867      0.895      0.628\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     12/100         0G      1.231      2.043      1.388         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.47s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.588      0.867      0.859      0.625\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     13/100         0G      1.052      2.231      1.369         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.54s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.589      0.867      0.861      0.626\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     14/100         0G      1.269      2.997      1.576         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.86it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.597      0.867      0.855      0.624\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     15/100         0G     0.8093      1.839      1.375         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.48s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.598      0.867      0.854      0.624\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     16/100         0G      1.373       2.54      1.818         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.41s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]","output_type":"stream"}]},{"cell_type":"code","source":"# final program\nimport cv2\nfrom ultralytics import YOLO\n\n# Load the trained YOLO model\nmodel = YOLO(\"yolo11n.pt\")  # Ensure this points to your trained model\n\n# Train the model\ntrain_results = model.train(\n    data=\"coco8.yaml\",  # path to dataset YAML\n    epochs=100,  # number of training epochs\n    imgsz=640,  # training image size\n    device=\"cpu\",  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu\n)\n\n# Evaluate model performance on the validation set\nmetrics = model.val()\n\n# Path to the input video file (replace with actual file name in /kaggle/input/)\nvideo_path = \"/kaggle/input/test-video/car-detection.mp4\"\n\n# Open the video file\ncap = cv2.VideoCapture(video_path)\n\nif not cap.isOpened():\n    print(f\"Error: Could not open video {video_path}\")\nelse:\n    print(f\"Successfully opened video: {video_path}\")\n\n# Get video details (frame width, height, FPS)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nprint(f\"Video FPS: {fps}, Width: {frame_width}, Height: {frame_height}\")\n\n# Define the codec and create VideoWriter object to save output video\noutput_path = \"/kaggle/working/output_video.mp4\"\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nframe_count = 0\n\n# Process the video frame by frame\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        print(\"Finished reading video.\")\n        break\n\n    # Perform object detection on the current frame\n    results = model(frame)\n\n    # Visualize and write the results on the frame\n    result_frame = results[0].plot()  # or use .show() for visualization\n    \n    # Write the processed frame to the output video\n    out.write(result_frame)\n    frame_count += 1\n\n    if frame_count % 10 == 0:  # Print every 10 frames to monitor progress\n        print(f\"Processed {frame_count} frames...\")\n\n# Release the video objects\ncap.release()\nout.release()\n\nprint(f\"Processed video saved as {output_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T09:32:38.813931Z","iopub.execute_input":"2024-10-10T09:32:38.814641Z","iopub.status.idle":"2024-10-10T09:38:40.629729Z","shell.execute_reply.started":"2024-10-10T09:32:38.814599Z","shell.execute_reply":"2024-10-10T09:38:40.628957Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Ultralytics 8.3.9 ðŸš€ Python-3.10.14 torch-2.4.0 CPU (Intel Xeon 2.00GHz)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=coco8.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \nYOLO11n summary: 319 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n\nTransferred 499/499 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114545266665724, max=1.0â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70eb605988ce473d9b96b2077afd48db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241010_093244-kq8bcdfj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/timmywang0207/Ultralytics/runs/kq8bcdfj' target=\"_blank\">train2</a></strong> to <a href='https://wandb.ai/timmywang0207/Ultralytics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/timmywang0207/Ultralytics' target=\"_blank\">https://wandb.ai/timmywang0207/Ultralytics</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/timmywang0207/Ultralytics/runs/kq8bcdfj' target=\"_blank\">https://wandb.ai/timmywang0207/Ultralytics/runs/kq8bcdfj</a>"},"metadata":{}},{"name":"stdout","text":"Freezing layer 'model.23.dfl.conv.weight'\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 292.58it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/datasets/coco8/labels/train.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 866.50it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/datasets/coco8/labels/val.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train2/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 0 dataloader workers\nLogging results to \u001b[1mruns/detect/train2\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/100         0G      1.365      3.625      1.786         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  2.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17       0.56       0.85       0.88      0.636\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/100         0G      1.181      2.736      1.443         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.53s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.559       0.85      0.892      0.638\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/100         0G      1.073      2.641      1.224         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.44s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.555       0.85      0.854      0.653\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/100         0G      1.254       3.31      1.567         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.539       0.85      0.856      0.655\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/100         0G      1.214      3.001      1.485         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.37s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.535       0.85      0.878      0.641\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/100         0G       0.99      2.694      1.333         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.47s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.548       0.85      0.878      0.641\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/100         0G     0.8189      2.642      1.309         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.44s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.822       0.65      0.858       0.63\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/100         0G      1.354      2.951      1.587         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.52s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.553      0.866       0.86      0.629\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      9/100         0G      1.018      2.218      1.433         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.43s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.551      0.867      0.872      0.631\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     10/100         0G     0.9819      2.952      1.376         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.58s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.589      0.867      0.887      0.631\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     11/100         0G       1.21       2.58      1.499         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.49s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.584      0.867      0.895      0.628\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     12/100         0G      1.231      2.043      1.388         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.43s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.588      0.867      0.859      0.625\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     13/100         0G      1.052      2.231      1.369         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.51s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.589      0.867      0.861      0.626\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     14/100         0G      1.269      2.997      1.576         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.48s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.597      0.867      0.855      0.624\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     15/100         0G     0.8093      1.839      1.375         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.49s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.598      0.867      0.854      0.624\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     16/100         0G      1.373       2.54      1.818         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.40s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.598      0.867      0.856      0.608\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     17/100         0G      1.005      2.344      1.411         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.48s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.603      0.867      0.857      0.604\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     18/100         0G      1.264      1.896      1.502         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.40s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.603      0.867      0.857      0.604\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     19/100         0G       1.08      1.879      1.379         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.58s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.619        0.7      0.873      0.617\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     20/100         0G     0.7695       1.37      1.144         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.48s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.78it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.619        0.7      0.873      0.617\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     21/100         0G      1.251      1.839      1.345         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.51s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.636        0.7      0.864      0.619\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     22/100         0G     0.8859      1.815      1.304         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.41s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.636        0.7      0.864      0.619\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     23/100         0G     0.9217      2.116      1.352         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.46s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.653      0.699      0.886       0.61\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     24/100         0G      1.217      2.104      1.538         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.653      0.699      0.886       0.61\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     25/100         0G      1.006      2.878      1.384         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.48s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17       0.66        0.7      0.877      0.613\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     26/100         0G      1.152      1.711      1.466         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.38s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17       0.66        0.7      0.877      0.613\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     27/100         0G      1.179      1.386      1.631         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.51s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.659        0.7      0.856      0.608\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     28/100         0G      0.961      2.159       1.42         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.659        0.7      0.856      0.608\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     29/100         0G      1.168      1.979      1.441         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.49s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.655        0.7      0.854       0.61\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     30/100         0G     0.9706      1.323      1.404         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.655        0.7      0.854       0.61\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     31/100         0G     0.9928      1.383      1.422         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.61s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.661      0.696      0.853      0.598\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     32/100         0G        1.2       2.18      1.392         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.44s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.661      0.696      0.853      0.598\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     33/100         0G     0.9065      1.548      1.166         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.50s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.665      0.698      0.853      0.598\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     34/100         0G      1.259      1.788      1.549         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.38s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.665      0.698      0.853      0.598\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     35/100         0G     0.7764      1.665       1.27         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.49s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.682      0.695       0.85      0.595\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     36/100         0G      1.176      1.853      1.483         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.35s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.682      0.695       0.85      0.595\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     37/100         0G     0.9014      1.644      1.316         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.41s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.698      0.688      0.852      0.577\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     38/100         0G     0.9053      1.303      1.352         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.40s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.698      0.688      0.852      0.577\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     39/100         0G     0.8369      1.046      1.258         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.46s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.706      0.601      0.824       0.56\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     40/100         0G     0.7942      1.169      1.205         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.706      0.601      0.824       0.56\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     41/100         0G      1.056      1.485      1.453         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.46s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.86it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.707      0.594      0.824      0.559\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     42/100         0G      1.008        1.5      1.289         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.44s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.707      0.594      0.824      0.559\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     43/100         0G     0.7529     0.9087      1.244         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.53s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.706      0.583      0.823      0.542\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     44/100         0G     0.8183      1.152      1.157         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.41s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.706      0.583      0.823      0.542\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     45/100         0G     0.7414      1.147      1.201         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.47s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.708      0.567      0.743      0.466\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     46/100         0G      0.811     0.9707      1.067         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.36s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.708      0.567      0.743      0.466\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     47/100         0G     0.8146      1.361      1.204         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.45s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.728      0.567      0.746      0.463\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     48/100         0G     0.7573      1.147      1.058         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.35s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.728      0.567      0.746      0.463\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     49/100         0G     0.8335      1.108      1.139         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.50s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.736      0.567      0.708       0.39\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     50/100         0G     0.7314     0.8773      1.222         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.40s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.736      0.567      0.708       0.39\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     51/100         0G      1.089      1.292      1.378         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.47s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.213        0.9        0.7      0.404\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     52/100         0G      1.085     0.9999      1.447         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.213        0.9        0.7      0.404\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     53/100         0G     0.9453       1.06      1.284         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.41s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.213        0.9        0.7      0.404\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     54/100         0G     0.9361      1.033      1.534         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.59s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.853      0.399      0.632      0.332\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     55/100         0G     0.6656     0.8278      1.147         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.853      0.399      0.632      0.332\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     56/100         0G      1.005     0.9805      1.347         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.44s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.853      0.399      0.632      0.332\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     57/100         0G     0.7954     0.9197       1.25         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.54s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.873      0.412      0.627      0.321\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     58/100         0G      0.859      1.021      1.247         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.44s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.873      0.412      0.627      0.321\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     59/100         0G     0.6068     0.6534      1.057         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.38s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.873      0.412      0.627      0.321\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     60/100         0G     0.7633     0.8165      1.127         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.58s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.853      0.399      0.581      0.294\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     61/100         0G     0.7329     0.8513      1.205         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.45s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.853      0.399      0.581      0.294\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     62/100         0G     0.7134     0.7383       1.06         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.37s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.853      0.399      0.581      0.294\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     63/100         0G     0.7692       1.46      1.142         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.50s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.855      0.397      0.544      0.249\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     64/100         0G     0.7491      1.173      1.141         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.855      0.397      0.544      0.249\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     65/100         0G     0.8001     0.9537      1.202         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.37s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.86it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.855      0.397      0.544      0.249\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     66/100         0G     0.7672       1.03      1.298         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.53s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.856      0.397      0.531      0.242\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     67/100         0G     0.7244     0.9221      1.071         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.856      0.397      0.531      0.242\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     68/100         0G     0.7571     0.7384      1.096         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.35s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.856      0.397      0.531      0.242\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     69/100         0G     0.5492     0.6565      1.063         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.37s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.855      0.396      0.554      0.243\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     70/100         0G     0.8688     0.9217       1.27         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.855      0.396      0.554      0.243\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     71/100         0G     0.8216     0.8048      1.314         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.40s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.855      0.396      0.554      0.243\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     72/100         0G     0.8799     0.7953      1.311         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.48s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.857      0.398      0.549      0.242\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     73/100         0G      1.213      2.375      1.564         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.38s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.857      0.398      0.549      0.242\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     74/100         0G     0.7761     0.6956      1.214         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.49s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.857      0.398      0.549      0.242\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     75/100         0G     0.5597     0.5557      1.008         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.47s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.856        0.4      0.548      0.238\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     76/100         0G     0.6677     0.7105      1.154         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.41s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.856        0.4      0.548      0.238\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     77/100         0G     0.6989     0.8122      1.068         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.36s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.856        0.4      0.548      0.238\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     78/100         0G      0.733     0.6812      1.099         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.43s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.857      0.398      0.547      0.238\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     79/100         0G     0.5211     0.5914     0.9687         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.35s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.96it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.857      0.398      0.547      0.238\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     80/100         0G     0.8963     0.7129      1.338         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.857      0.398      0.547      0.238\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     81/100         0G      0.678     0.9206      1.145         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.46s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.92it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.875      0.411      0.549      0.235\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     82/100         0G     0.5347     0.5012      0.962         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.875      0.411      0.549      0.235\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     83/100         0G     0.6343     0.7573      1.112         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.875      0.411      0.549      0.235\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     84/100         0G     0.7579      1.083      1.161         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.50s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.875      0.408       0.53      0.234\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     85/100         0G     0.8091     0.9764      1.197         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.40s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.875      0.408       0.53      0.234\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     86/100         0G     0.8652     0.9209      1.324         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.38s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.875      0.408       0.53      0.234\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     87/100         0G     0.5566      0.753      1.064         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.37s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.875      0.408       0.53      0.234\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     88/100         0G     0.5681     0.7931      1.048         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.43s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.876      0.406       0.53      0.237\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     89/100         0G     0.8294     0.7668      1.356         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.876      0.406       0.53      0.237\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     90/100         0G     0.7665     0.6689      1.156         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.38s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.876      0.406       0.53      0.237\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Closing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     91/100         0G     0.6122     0.5938      1.147         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.34s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.876      0.406       0.53      0.237\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     92/100         0G     0.5917        0.6      1.121         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.876      0.409      0.519      0.233\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     93/100         0G     0.6535     0.6054     0.9352         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.38s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.876      0.409      0.519      0.233\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     94/100         0G      0.604     0.5294      1.145         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.35s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.876      0.409      0.519      0.233\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     95/100         0G      0.526     0.4705      0.895         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.40s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.876      0.409      0.519      0.233\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     96/100         0G     0.6807     0.6366     0.9682         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.48s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.851      0.415      0.549      0.247\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     97/100         0G     0.4814     0.5075     0.9394         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.91it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.851      0.415      0.549      0.247\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     98/100         0G      0.429      0.429     0.9343         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.34s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.851      0.415      0.549      0.247\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     99/100         0G     0.6197     0.5357      1.029         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.31s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.851      0.415      0.549      0.247\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"    100/100         0G     0.5137     0.4584     0.9579         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.46s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.667      0.416      0.532      0.246\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n100 epochs completed in 0.081 hours.\nOptimizer stripped from runs/detect/train2/weights/last.pt, 5.6MB\nOptimizer stripped from runs/detect/train2/weights/best.pt, 5.6MB\n\nValidating runs/detect/train2/weights/best.pt...\nUltralytics 8.3.9 ðŸš€ Python-3.10.14 torch-2.4.0 CPU (Intel Xeon 2.00GHz)\nYOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.541       0.85      0.856      0.655\n                person          3         10      0.551        0.6      0.624      0.306\n                   dog          1          1      0.535          1      0.995      0.796\n                 horse          1          2      0.414          1      0.995      0.675\n              elephant          1          2      0.355        0.5      0.529      0.261\n              umbrella          1          1       0.56          1      0.995      0.995\n          potted plant          1          1      0.835          1      0.995      0.895\nSpeed: 1.2ms preprocess, 110.6ms inference, 0.0ms loss, 1.7ms postprocess per image\nResults saved to \u001b[1mruns/detect/train2\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='6.684 MB of 10.150 MB uploaded\\r'), FloatProgress(value=0.6584949335824902, max=1.â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc820371fff5411b8a755e0a6da82bb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–†â–…â–…â–…â–„â–ƒâ–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–„â–„â–„â–ƒâ–</td></tr><tr><td>lr/pg2</td><td>â–‚â–ƒâ–„â–„â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–ƒâ–‚â–‚â–</td></tr><tr><td>metrics/mAP50(B)</td><td>â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–…â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‡</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–„â–„â–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>metrics/precision(B)</td><td>â–…â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/recall(B)</td><td>â–‡â–…â–ˆâ–ˆâ–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–„â–ƒâ–ƒâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>train/box_loss</td><td>â–†â–†â–‡â–ˆâ–…â–‡â–…â–‡â–ˆâ–…â–ƒâ–„â–…â–†â–„â–„â–ƒâ–†â–„â–„â–†â–…â–‚â–…â–‚â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–„â–„â–‚â–‚â–‚â–‚â–â–</td></tr><tr><td>train/cls_loss</td><td>â–‡â–†â–ˆâ–‡â–…â–„â–ƒâ–„â–„â–ƒâ–ƒâ–…â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–â–</td></tr><tr><td>train/dfl_loss</td><td>â–‡â–‡â–…â–…â–†â–†â–†â–…â–ˆâ–†â–†â–†â–†â–ˆâ–‡â–„â–„â–„â–„â–‚â–‡â–ˆâ–‚â–ƒâ–„â–ƒâ–…â–‚â–ƒâ–‚â–…â–ˆâ–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–‚</td></tr><tr><td>val/box_loss</td><td>â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚â–‚â–„â–„â–„â–„â–„â–„â–…â–…â–†â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†</td></tr><tr><td>val/cls_loss</td><td>â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡</td></tr><tr><td>val/dfl_loss</td><td>â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–„â–„â–…â–…â–…â–…â–„â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0</td></tr><tr><td>lr/pg1</td><td>0.0</td></tr><tr><td>lr/pg2</td><td>0.0</td></tr><tr><td>metrics/mAP50(B)</td><td>0.85565</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.65479</td></tr><tr><td>metrics/precision(B)</td><td>0.5415</td></tr><tr><td>metrics/recall(B)</td><td>0.85</td></tr><tr><td>model/GFLOPs</td><td>6.614</td></tr><tr><td>model/parameters</td><td>2624080</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>116.931</td></tr><tr><td>train/box_loss</td><td>0.51373</td></tr><tr><td>train/cls_loss</td><td>0.45838</td></tr><tr><td>train/dfl_loss</td><td>0.95792</td></tr><tr><td>val/box_loss</td><td>1.74371</td></tr><tr><td>val/cls_loss</td><td>2.0522</td></tr><tr><td>val/dfl_loss</td><td>1.45089</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">train2</strong> at: <a href='https://wandb.ai/timmywang0207/Ultralytics/runs/kq8bcdfj' target=\"_blank\">https://wandb.ai/timmywang0207/Ultralytics/runs/kq8bcdfj</a><br/> View project at: <a href='https://wandb.ai/timmywang0207/Ultralytics' target=\"_blank\">https://wandb.ai/timmywang0207/Ultralytics</a><br/>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 20 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241010_093244-kq8bcdfj/logs</code>"},"metadata":{}},{"name":"stdout","text":"Ultralytics 8.3.9 ðŸš€ Python-3.10.14 torch-2.4.0 CPU (Intel Xeon 2.00GHz)\nYOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<?, ?it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.541       0.85      0.856      0.655\n                person          3         10      0.551        0.6      0.624      0.306\n                   dog          1          1      0.535          1      0.995      0.796\n                 horse          1          2      0.414          1      0.995      0.675\n              elephant          1          2      0.355        0.5      0.529      0.261\n              umbrella          1          1       0.56          1      0.995      0.995\n          potted plant          1          1      0.835          1      0.995      0.895\nSpeed: 1.2ms preprocess, 98.4ms inference, 0.0ms loss, 1.7ms postprocess per image\nResults saved to \u001b[1mruns/detect/train22\u001b[0m\nSuccessfully opened video: /kaggle/input/test-video/car-detection.mp4\nVideo FPS: 12.5, Width: 768, Height: 432\n\n0: 384x640 (no detections), 107.3ms\nSpeed: 3.7ms preprocess, 107.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.6ms\nSpeed: 2.3ms preprocess, 74.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 73.5ms\nSpeed: 2.4ms preprocess, 73.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.5ms\nSpeed: 2.3ms preprocess, 77.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.1ms\nSpeed: 2.3ms preprocess, 74.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.9ms\nSpeed: 2.3ms preprocess, 74.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.6ms\nSpeed: 2.3ms preprocess, 74.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.2ms\nSpeed: 2.5ms preprocess, 77.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.7ms\nSpeed: 2.3ms preprocess, 77.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.5ms\nSpeed: 2.3ms preprocess, 77.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 10 frames...\n\n0: 384x640 (no detections), 74.3ms\nSpeed: 2.4ms preprocess, 74.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.1ms\nSpeed: 2.3ms preprocess, 77.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.4ms\nSpeed: 2.3ms preprocess, 78.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.0ms\nSpeed: 2.4ms preprocess, 79.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.6ms\nSpeed: 2.4ms preprocess, 78.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.7ms\nSpeed: 2.4ms preprocess, 76.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.9ms\nSpeed: 2.3ms preprocess, 78.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.8ms\nSpeed: 2.3ms preprocess, 76.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.3ms\nSpeed: 2.5ms preprocess, 75.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.7ms\nSpeed: 2.4ms preprocess, 78.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 20 frames...\n\n0: 384x640 (no detections), 78.6ms\nSpeed: 2.4ms preprocess, 78.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.7ms\nSpeed: 2.3ms preprocess, 76.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 73.6ms\nSpeed: 2.3ms preprocess, 73.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.0ms\nSpeed: 2.3ms preprocess, 76.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.9ms\nSpeed: 2.3ms preprocess, 74.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.4ms\nSpeed: 2.4ms preprocess, 76.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 73.6ms\nSpeed: 2.3ms preprocess, 73.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 80.4ms\nSpeed: 2.3ms preprocess, 80.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.1ms\nSpeed: 2.6ms preprocess, 79.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.6ms\nSpeed: 2.4ms preprocess, 78.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 30 frames...\n\n0: 384x640 (no detections), 87.6ms\nSpeed: 2.3ms preprocess, 87.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 82.9ms\nSpeed: 2.7ms preprocess, 82.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 81.7ms\nSpeed: 2.5ms preprocess, 81.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 80.8ms\nSpeed: 2.4ms preprocess, 80.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 80.5ms\nSpeed: 2.4ms preprocess, 80.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 82.2ms\nSpeed: 2.4ms preprocess, 82.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 82.9ms\nSpeed: 2.4ms preprocess, 82.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.0ms\nSpeed: 2.4ms preprocess, 79.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 82.3ms\nSpeed: 2.4ms preprocess, 82.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 80.5ms\nSpeed: 2.5ms preprocess, 80.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 40 frames...\n\n0: 384x640 (no detections), 81.4ms\nSpeed: 2.5ms preprocess, 81.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.2ms\nSpeed: 2.3ms preprocess, 79.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.6ms\nSpeed: 2.3ms preprocess, 78.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 80.5ms\nSpeed: 2.4ms preprocess, 80.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.7ms\nSpeed: 2.4ms preprocess, 74.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 82.2ms\nSpeed: 2.3ms preprocess, 82.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.1ms\nSpeed: 2.5ms preprocess, 79.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.2ms\nSpeed: 2.3ms preprocess, 77.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.7ms\nSpeed: 2.3ms preprocess, 79.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.6ms\nSpeed: 2.4ms preprocess, 79.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 50 frames...\n\n0: 384x640 (no detections), 78.9ms\nSpeed: 2.4ms preprocess, 78.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.8ms\nSpeed: 2.3ms preprocess, 75.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.3ms\nSpeed: 2.4ms preprocess, 74.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.8ms\nSpeed: 2.3ms preprocess, 75.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.8ms\nSpeed: 2.3ms preprocess, 74.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.2ms\nSpeed: 2.4ms preprocess, 78.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.9ms\nSpeed: 2.4ms preprocess, 79.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 person, 81.6ms\nSpeed: 2.5ms preprocess, 81.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 person, 76.5ms\nSpeed: 2.4ms preprocess, 76.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.3ms\nSpeed: 2.3ms preprocess, 79.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 60 frames...\n\n0: 384x640 (no detections), 75.3ms\nSpeed: 2.4ms preprocess, 75.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 80.0ms\nSpeed: 2.4ms preprocess, 80.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 78.0ms\nSpeed: 2.4ms preprocess, 78.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.3ms\nSpeed: 2.4ms preprocess, 74.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.8ms\nSpeed: 2.4ms preprocess, 78.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 bus, 80.9ms\nSpeed: 2.4ms preprocess, 80.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 76.4ms\nSpeed: 2.3ms preprocess, 76.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.9ms\nSpeed: 2.3ms preprocess, 74.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 73.7ms\nSpeed: 2.4ms preprocess, 73.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.8ms\nSpeed: 2.3ms preprocess, 74.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 70 frames...\n\n0: 384x640 1 cell phone, 79.0ms\nSpeed: 2.3ms preprocess, 79.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.8ms\nSpeed: 2.4ms preprocess, 78.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 83.7ms\nSpeed: 2.3ms preprocess, 83.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 77.7ms\nSpeed: 2.3ms preprocess, 77.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 96.3ms\nSpeed: 2.4ms preprocess, 96.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 71.9ms\nSpeed: 2.9ms preprocess, 71.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 68.3ms\nSpeed: 1.9ms preprocess, 68.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 78.2ms\nSpeed: 2.3ms preprocess, 78.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 79.0ms\nSpeed: 2.3ms preprocess, 79.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 79.0ms\nSpeed: 2.4ms preprocess, 79.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 80 frames...\n\n0: 384x640 1 cell phone, 78.9ms\nSpeed: 2.4ms preprocess, 78.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 79.1ms\nSpeed: 2.3ms preprocess, 79.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 76.7ms\nSpeed: 2.3ms preprocess, 76.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 80.1ms\nSpeed: 2.3ms preprocess, 80.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 77.8ms\nSpeed: 2.4ms preprocess, 77.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 75.5ms\nSpeed: 2.3ms preprocess, 75.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 78.1ms\nSpeed: 2.3ms preprocess, 78.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 77.8ms\nSpeed: 2.4ms preprocess, 77.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 79.4ms\nSpeed: 2.3ms preprocess, 79.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 77.7ms\nSpeed: 2.5ms preprocess, 77.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 90 frames...\n\n0: 384x640 1 cell phone, 77.0ms\nSpeed: 2.3ms preprocess, 77.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 77.4ms\nSpeed: 2.4ms preprocess, 77.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 77.0ms\nSpeed: 2.3ms preprocess, 77.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 78.5ms\nSpeed: 2.4ms preprocess, 78.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 79.4ms\nSpeed: 2.4ms preprocess, 79.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 77.3ms\nSpeed: 2.3ms preprocess, 77.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 74.9ms\nSpeed: 2.4ms preprocess, 74.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 73.3ms\nSpeed: 2.3ms preprocess, 73.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 77.3ms\nSpeed: 2.3ms preprocess, 77.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 78.5ms\nSpeed: 2.3ms preprocess, 78.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 100 frames...\n\n0: 384x640 1 cell phone, 76.3ms\nSpeed: 2.4ms preprocess, 76.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.8ms\nSpeed: 2.3ms preprocess, 76.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 76.5ms\nSpeed: 2.3ms preprocess, 76.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 81.5ms\nSpeed: 2.4ms preprocess, 81.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 73.4ms\nSpeed: 2.4ms preprocess, 73.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.0ms\nSpeed: 2.3ms preprocess, 74.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.3ms\nSpeed: 2.9ms preprocess, 77.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.5ms\nSpeed: 2.4ms preprocess, 75.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 99.6ms\nSpeed: 2.3ms preprocess, 99.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 84.3ms\nSpeed: 3.3ms preprocess, 84.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 110 frames...\n\n0: 384x640 (no detections), 80.9ms\nSpeed: 2.4ms preprocess, 80.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 86.5ms\nSpeed: 2.4ms preprocess, 86.5ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 83.5ms\nSpeed: 2.8ms preprocess, 83.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 101.1ms\nSpeed: 2.5ms preprocess, 101.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 102.1ms\nSpeed: 2.6ms preprocess, 102.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 101.7ms\nSpeed: 2.4ms preprocess, 101.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 81.0ms\nSpeed: 2.7ms preprocess, 81.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 81.9ms\nSpeed: 3.2ms preprocess, 81.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 83.7ms\nSpeed: 2.9ms preprocess, 83.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 81.5ms\nSpeed: 2.8ms preprocess, 81.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 120 frames...\n\n0: 384x640 (no detections), 83.2ms\nSpeed: 2.7ms preprocess, 83.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 83.5ms\nSpeed: 3.2ms preprocess, 83.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 85.0ms\nSpeed: 2.8ms preprocess, 85.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 84.7ms\nSpeed: 2.9ms preprocess, 84.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 83.2ms\nSpeed: 2.7ms preprocess, 83.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 87.8ms\nSpeed: 2.7ms preprocess, 87.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.9ms\nSpeed: 3.0ms preprocess, 78.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 81.5ms\nSpeed: 2.7ms preprocess, 81.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 83.7ms\nSpeed: 2.7ms preprocess, 83.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 83.0ms\nSpeed: 2.7ms preprocess, 83.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 130 frames...\n\n0: 384x640 (no detections), 84.3ms\nSpeed: 2.9ms preprocess, 84.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 70.3ms\nSpeed: 2.8ms preprocess, 70.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 71.2ms\nSpeed: 2.6ms preprocess, 71.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.5ms\nSpeed: 2.7ms preprocess, 75.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 80.6ms\nSpeed: 2.4ms preprocess, 80.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 81.4ms\nSpeed: 2.4ms preprocess, 81.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 82.4ms\nSpeed: 2.5ms preprocess, 82.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.3ms\nSpeed: 2.8ms preprocess, 78.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.1ms\nSpeed: 2.4ms preprocess, 76.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.8ms\nSpeed: 2.4ms preprocess, 76.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 140 frames...\n\n0: 384x640 (no detections), 79.8ms\nSpeed: 2.3ms preprocess, 79.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.0ms\nSpeed: 2.4ms preprocess, 79.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.8ms\nSpeed: 2.3ms preprocess, 79.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 81.7ms\nSpeed: 2.4ms preprocess, 81.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 80.5ms\nSpeed: 2.3ms preprocess, 80.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 81.3ms\nSpeed: 2.4ms preprocess, 81.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.4ms\nSpeed: 2.4ms preprocess, 77.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.4ms\nSpeed: 2.3ms preprocess, 78.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.7ms\nSpeed: 2.4ms preprocess, 79.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.8ms\nSpeed: 2.4ms preprocess, 75.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 150 frames...\n\n0: 384x640 (no detections), 77.1ms\nSpeed: 2.3ms preprocess, 77.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.6ms\nSpeed: 2.3ms preprocess, 76.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.4ms\nSpeed: 2.4ms preprocess, 74.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.9ms\nSpeed: 2.4ms preprocess, 75.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 73.8ms\nSpeed: 2.5ms preprocess, 73.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 73.8ms\nSpeed: 2.3ms preprocess, 73.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.5ms\nSpeed: 2.3ms preprocess, 75.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 71.5ms\nSpeed: 2.3ms preprocess, 71.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.5ms\nSpeed: 2.3ms preprocess, 75.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.9ms\nSpeed: 2.3ms preprocess, 77.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 160 frames...\n\n0: 384x640 (no detections), 79.4ms\nSpeed: 2.4ms preprocess, 79.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.5ms\nSpeed: 2.3ms preprocess, 74.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 73.3ms\nSpeed: 2.3ms preprocess, 73.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.8ms\nSpeed: 2.3ms preprocess, 75.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.5ms\nSpeed: 2.4ms preprocess, 77.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.5ms\nSpeed: 2.4ms preprocess, 77.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.5ms\nSpeed: 2.3ms preprocess, 75.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.3ms\nSpeed: 2.3ms preprocess, 78.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.3ms\nSpeed: 2.3ms preprocess, 78.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.3ms\nSpeed: 2.4ms preprocess, 74.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 170 frames...\n\n0: 384x640 (no detections), 77.6ms\nSpeed: 2.4ms preprocess, 77.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.4ms\nSpeed: 2.4ms preprocess, 78.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.9ms\nSpeed: 2.3ms preprocess, 75.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.9ms\nSpeed: 2.3ms preprocess, 76.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 73.9ms\nSpeed: 2.3ms preprocess, 73.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 73.3ms\nSpeed: 2.3ms preprocess, 73.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.3ms\nSpeed: 2.3ms preprocess, 75.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.2ms\nSpeed: 2.6ms preprocess, 75.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.8ms\nSpeed: 2.4ms preprocess, 75.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 79.3ms\nSpeed: 2.5ms preprocess, 79.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 180 frames...\n\n0: 384x640 (no detections), 77.5ms\nSpeed: 2.5ms preprocess, 77.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 82.0ms\nSpeed: 1.8ms preprocess, 82.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 86.4ms\nSpeed: 2.4ms preprocess, 86.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 121.5ms\nSpeed: 2.7ms preprocess, 121.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 78.9ms\nSpeed: 3.1ms preprocess, 78.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 71.5ms\nSpeed: 2.7ms preprocess, 71.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 76.2ms\nSpeed: 2.4ms preprocess, 76.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 74.3ms\nSpeed: 2.4ms preprocess, 74.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cup, 74.9ms\nSpeed: 2.5ms preprocess, 74.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cup, 75.3ms\nSpeed: 1.9ms preprocess, 75.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 190 frames...\n\n0: 384x640 (no detections), 74.1ms\nSpeed: 1.9ms preprocess, 74.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 sports ball, 73.9ms\nSpeed: 2.5ms preprocess, 73.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 person, 1 cell phone, 79.5ms\nSpeed: 2.0ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 76.5ms\nSpeed: 2.4ms preprocess, 76.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 78.2ms\nSpeed: 2.5ms preprocess, 78.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 75.8ms\nSpeed: 2.5ms preprocess, 75.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 72.7ms\nSpeed: 2.4ms preprocess, 72.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 suitcase, 70.4ms\nSpeed: 2.4ms preprocess, 70.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 suitcase, 75.1ms\nSpeed: 2.4ms preprocess, 75.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 suitcase, 74.2ms\nSpeed: 2.7ms preprocess, 74.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 200 frames...\n\n0: 384x640 1 suitcase, 1 cell phone, 72.7ms\nSpeed: 2.7ms preprocess, 72.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 suitcase, 1 cell phone, 72.3ms\nSpeed: 2.4ms preprocess, 72.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 68.5ms\nSpeed: 2.6ms preprocess, 68.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 72.0ms\nSpeed: 2.7ms preprocess, 72.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 73.9ms\nSpeed: 2.7ms preprocess, 73.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 68.5ms\nSpeed: 2.4ms preprocess, 68.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 68.0ms\nSpeed: 2.7ms preprocess, 68.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 70.0ms\nSpeed: 2.4ms preprocess, 70.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 69.2ms\nSpeed: 2.5ms preprocess, 69.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 71.3ms\nSpeed: 2.4ms preprocess, 71.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 210 frames...\n\n0: 384x640 2 cell phones, 70.0ms\nSpeed: 2.5ms preprocess, 70.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 73.8ms\nSpeed: 1.9ms preprocess, 73.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 77.4ms\nSpeed: 2.4ms preprocess, 77.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 74.4ms\nSpeed: 2.6ms preprocess, 74.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 73.2ms\nSpeed: 2.6ms preprocess, 73.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 71.4ms\nSpeed: 2.6ms preprocess, 71.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 73.7ms\nSpeed: 2.6ms preprocess, 73.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 71.9ms\nSpeed: 2.7ms preprocess, 71.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 73.0ms\nSpeed: 2.6ms preprocess, 73.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 2 cell phones, 71.1ms\nSpeed: 2.6ms preprocess, 71.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 220 frames...\n\n0: 384x640 1 car, 2 cell phones, 72.1ms\nSpeed: 2.5ms preprocess, 72.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 1 bus, 72.5ms\nSpeed: 2.3ms preprocess, 72.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 1 bus, 74.1ms\nSpeed: 2.9ms preprocess, 74.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 1 cell phone, 71.2ms\nSpeed: 2.6ms preprocess, 71.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 1 cell phone, 70.9ms\nSpeed: 2.4ms preprocess, 70.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 1 cell phone, 71.5ms\nSpeed: 2.6ms preprocess, 71.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 69.6ms\nSpeed: 2.6ms preprocess, 69.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 74.0ms\nSpeed: 2.4ms preprocess, 74.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 1 cell phone, 73.6ms\nSpeed: 2.6ms preprocess, 73.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 71.8ms\nSpeed: 2.8ms preprocess, 71.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 230 frames...\n\n0: 384x640 1 cell phone, 69.0ms\nSpeed: 2.4ms preprocess, 69.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 68.1ms\nSpeed: 2.4ms preprocess, 68.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 68.4ms\nSpeed: 2.4ms preprocess, 68.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 1 cell phone, 69.7ms\nSpeed: 2.4ms preprocess, 69.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 68.6ms\nSpeed: 2.6ms preprocess, 68.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 70.8ms\nSpeed: 2.6ms preprocess, 70.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 73.1ms\nSpeed: 2.6ms preprocess, 73.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 72.0ms\nSpeed: 2.6ms preprocess, 72.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 69.3ms\nSpeed: 2.4ms preprocess, 69.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.6ms\nSpeed: 2.6ms preprocess, 76.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 240 frames...\n\n0: 384x640 (no detections), 73.7ms\nSpeed: 2.6ms preprocess, 73.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 69.1ms\nSpeed: 2.8ms preprocess, 69.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 75.9ms\nSpeed: 2.4ms preprocess, 75.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 72.8ms\nSpeed: 2.5ms preprocess, 72.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 68.3ms\nSpeed: 2.4ms preprocess, 68.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 69.2ms\nSpeed: 2.6ms preprocess, 69.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 68.9ms\nSpeed: 2.6ms preprocess, 68.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 70.1ms\nSpeed: 2.4ms preprocess, 70.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 73.5ms\nSpeed: 2.5ms preprocess, 73.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 72.8ms\nSpeed: 2.5ms preprocess, 72.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 250 frames...\n\n0: 384x640 (no detections), 69.4ms\nSpeed: 2.4ms preprocess, 69.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 69.2ms\nSpeed: 2.6ms preprocess, 69.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 68.5ms\nSpeed: 2.1ms preprocess, 68.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 69.3ms\nSpeed: 2.5ms preprocess, 69.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 70.5ms\nSpeed: 2.6ms preprocess, 70.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 68.7ms\nSpeed: 2.6ms preprocess, 68.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 69.7ms\nSpeed: 2.7ms preprocess, 69.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 69.2ms\nSpeed: 2.6ms preprocess, 69.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 69.8ms\nSpeed: 2.6ms preprocess, 69.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 68.8ms\nSpeed: 1.9ms preprocess, 68.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 260 frames...\n\n0: 384x640 1 airplane, 70.8ms\nSpeed: 2.5ms preprocess, 70.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 72.6ms\nSpeed: 2.4ms preprocess, 72.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 70.6ms\nSpeed: 2.6ms preprocess, 70.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 74.5ms\nSpeed: 2.5ms preprocess, 74.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 75.0ms\nSpeed: 2.6ms preprocess, 75.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 70.8ms\nSpeed: 2.7ms preprocess, 70.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 72.6ms\nSpeed: 2.8ms preprocess, 72.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 71.7ms\nSpeed: 2.6ms preprocess, 71.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 70.9ms\nSpeed: 2.4ms preprocess, 70.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 72.4ms\nSpeed: 2.4ms preprocess, 72.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 270 frames...\n\n0: 384x640 1 airplane, 73.0ms\nSpeed: 1.8ms preprocess, 73.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 72.5ms\nSpeed: 2.7ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 73.8ms\nSpeed: 2.0ms preprocess, 73.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 72.5ms\nSpeed: 2.7ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 68.4ms\nSpeed: 2.4ms preprocess, 68.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 69.8ms\nSpeed: 2.5ms preprocess, 69.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 76.7ms\nSpeed: 2.2ms preprocess, 76.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 82.9ms\nSpeed: 3.0ms preprocess, 82.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 75.0ms\nSpeed: 2.9ms preprocess, 75.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 70.5ms\nSpeed: 2.3ms preprocess, 70.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 280 frames...\n\n0: 384x640 1 airplane, 71.7ms\nSpeed: 2.6ms preprocess, 71.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 74.9ms\nSpeed: 2.4ms preprocess, 74.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 70.5ms\nSpeed: 2.4ms preprocess, 70.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 69.5ms\nSpeed: 2.7ms preprocess, 69.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 72.8ms\nSpeed: 2.5ms preprocess, 72.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 71.4ms\nSpeed: 2.4ms preprocess, 71.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 71.7ms\nSpeed: 2.7ms preprocess, 71.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 71.3ms\nSpeed: 2.4ms preprocess, 71.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 72.8ms\nSpeed: 2.4ms preprocess, 72.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 72.6ms\nSpeed: 2.4ms preprocess, 72.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 290 frames...\n\n0: 384x640 1 airplane, 68.9ms\nSpeed: 2.4ms preprocess, 68.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 68.5ms\nSpeed: 2.4ms preprocess, 68.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 68.9ms\nSpeed: 2.4ms preprocess, 68.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 70.7ms\nSpeed: 2.4ms preprocess, 70.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 69.8ms\nSpeed: 2.4ms preprocess, 69.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 70.2ms\nSpeed: 2.4ms preprocess, 70.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 73.9ms\nSpeed: 2.5ms preprocess, 73.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 72.7ms\nSpeed: 2.5ms preprocess, 72.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 79.4ms\nSpeed: 2.7ms preprocess, 79.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 73.3ms\nSpeed: 2.4ms preprocess, 73.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 300 frames...\n\n0: 384x640 1 airplane, 96.3ms\nSpeed: 2.4ms preprocess, 96.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 84.9ms\nSpeed: 4.1ms preprocess, 84.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 79.6ms\nSpeed: 2.4ms preprocess, 79.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 77.7ms\nSpeed: 2.3ms preprocess, 77.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 75.9ms\nSpeed: 2.4ms preprocess, 75.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 79.1ms\nSpeed: 2.4ms preprocess, 79.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 83.1ms\nSpeed: 2.5ms preprocess, 83.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 81.6ms\nSpeed: 2.4ms preprocess, 81.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 79.9ms\nSpeed: 2.3ms preprocess, 79.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 78.7ms\nSpeed: 2.4ms preprocess, 78.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 310 frames...\n\n0: 384x640 1 airplane, 82.9ms\nSpeed: 2.4ms preprocess, 82.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 79.0ms\nSpeed: 2.5ms preprocess, 79.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 77.4ms\nSpeed: 2.4ms preprocess, 77.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 74.9ms\nSpeed: 2.3ms preprocess, 74.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 74.5ms\nSpeed: 2.3ms preprocess, 74.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 airplane, 75.2ms\nSpeed: 2.4ms preprocess, 75.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.2ms\nSpeed: 2.3ms preprocess, 76.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.0ms\nSpeed: 2.3ms preprocess, 76.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 81.5ms\nSpeed: 2.4ms preprocess, 81.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 76.5ms\nSpeed: 2.4ms preprocess, 76.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 320 frames...\n\n0: 384x640 (no detections), 77.6ms\nSpeed: 2.3ms preprocess, 77.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cup, 1 spoon, 77.5ms\nSpeed: 2.3ms preprocess, 77.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 bottle, 76.0ms\nSpeed: 2.3ms preprocess, 76.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 76.0ms\nSpeed: 2.3ms preprocess, 76.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 75.8ms\nSpeed: 2.4ms preprocess, 75.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 77.1ms\nSpeed: 2.3ms preprocess, 77.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 79.3ms\nSpeed: 2.4ms preprocess, 79.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 75.7ms\nSpeed: 2.3ms preprocess, 75.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 81.5ms\nSpeed: 2.4ms preprocess, 81.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 79.0ms\nSpeed: 2.4ms preprocess, 79.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 330 frames...\n\n0: 384x640 1 cell phone, 77.5ms\nSpeed: 2.4ms preprocess, 77.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 79.8ms\nSpeed: 2.4ms preprocess, 79.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 80.7ms\nSpeed: 2.4ms preprocess, 80.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 78.4ms\nSpeed: 2.3ms preprocess, 78.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 77.1ms\nSpeed: 2.4ms preprocess, 77.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 75.6ms\nSpeed: 2.3ms preprocess, 75.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 77.3ms\nSpeed: 2.4ms preprocess, 77.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 79.2ms\nSpeed: 4.2ms preprocess, 79.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 73.6ms\nSpeed: 2.3ms preprocess, 73.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 76.2ms\nSpeed: 2.3ms preprocess, 76.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 340 frames...\n\n0: 384x640 1 cell phone, 79.8ms\nSpeed: 2.3ms preprocess, 79.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 cell phone, 77.3ms\nSpeed: 2.3ms preprocess, 77.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.1ms\nSpeed: 2.4ms preprocess, 79.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 77.2ms\nSpeed: 2.3ms preprocess, 77.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 75.7ms\nSpeed: 2.4ms preprocess, 75.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 78.3ms\nSpeed: 2.3ms preprocess, 78.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 1 car, 76.5ms\nSpeed: 2.4ms preprocess, 76.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 80.2ms\nSpeed: 2.3ms preprocess, 80.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.9ms\nSpeed: 2.5ms preprocess, 78.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.7ms\nSpeed: 2.4ms preprocess, 77.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 350 frames...\n\n0: 384x640 (no detections), 80.5ms\nSpeed: 2.4ms preprocess, 80.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 80.4ms\nSpeed: 2.3ms preprocess, 80.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.0ms\nSpeed: 2.4ms preprocess, 76.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 80.6ms\nSpeed: 2.4ms preprocess, 80.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 76.2ms\nSpeed: 2.4ms preprocess, 76.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 74.6ms\nSpeed: 2.4ms preprocess, 74.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.6ms\nSpeed: 2.3ms preprocess, 77.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.1ms\nSpeed: 2.5ms preprocess, 79.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.4ms\nSpeed: 2.4ms preprocess, 78.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 81.9ms\nSpeed: 2.4ms preprocess, 81.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 360 frames...\n\n0: 384x640 (no detections), 81.6ms\nSpeed: 2.4ms preprocess, 81.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.8ms\nSpeed: 2.3ms preprocess, 78.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.4ms\nSpeed: 2.4ms preprocess, 79.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.9ms\nSpeed: 2.4ms preprocess, 79.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.0ms\nSpeed: 2.4ms preprocess, 77.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.2ms\nSpeed: 2.4ms preprocess, 79.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.4ms\nSpeed: 2.4ms preprocess, 77.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 77.7ms\nSpeed: 2.4ms preprocess, 77.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.7ms\nSpeed: 2.4ms preprocess, 78.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 82.2ms\nSpeed: 2.4ms preprocess, 82.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\nProcessed 370 frames...\n\n0: 384x640 (no detections), 81.2ms\nSpeed: 2.4ms preprocess, 81.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 78.4ms\nSpeed: 2.4ms preprocess, 78.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 79.4ms\nSpeed: 2.3ms preprocess, 79.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 81.8ms\nSpeed: 2.4ms preprocess, 81.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 81.6ms\nSpeed: 2.4ms preprocess, 81.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 81.2ms\nSpeed: 2.4ms preprocess, 81.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 (no detections), 81.0ms\nSpeed: 2.3ms preprocess, 81.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\nFinished reading video.\nProcessed video saved as /kaggle/working/output_video.mp4\n","output_type":"stream"}]}]}